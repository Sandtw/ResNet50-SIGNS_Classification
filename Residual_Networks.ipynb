{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construirá una red convolucional muy profunda, utilizando redes residuales (ResNets). En teoría, las redes muy profundas pueden representar funciones muy complejas; pero en la práctica, son difíciles de entrenar. Las redes residuales, presentadas por [He et al.](https://arxiv.org/pdf/1512.03385.pdf), le permiten entrenar redes mucho más profundas de lo que antes era factible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El problema de las redes neuronales muy profundas\n",
    "\n",
    "En los últimos años, las redes neuronales se han vuelto mucho más profundas, con redes de última generación que han pasado de tener solo unas pocas capas (por ejemplo, AlexNet) a más de cien capas.\n",
    "\n",
    "* Sin embargo, usar una red más profunda no siempre ayuda. Una gran barrera para entrenarlos son los gradientes que se desvanecen: las redes muy profundas a menudo tienen una señal de gradiente que llega a cero rápidamente, lo que hace que el descenso de gradiente sea prohibitivamente lento.\n",
    "\n",
    "* Más específicamente, durante el descenso del gradiente, a medida que retropropaga de la capa final a la primera capa, está multiplicando por la matriz de peso en cada paso y, por lo tanto, el gradiente puede disminuir exponencialmente rápidamente hasta cero (o, en casos raros, crecer exponencialmente rápido y \"explotar\", al ganar valores muy grandes).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construyendo una Residual Network\n",
    "\n",
    "En ResNet, un \"shortcut\" o un \"skip connection\" permite al modelo omitir capas:\n",
    "\n",
    "<img src=\"images/skip_connection_kiank.png\" style=\"width:650px;height:200px;\">\n",
    "\n",
    "La imagen de la derecha agrega un acceso directo a la ruta principal. Al apilar estos bloques ResNet uno encima del otro, puede formar una red muy profunda.\n",
    "\n",
    "Tener bloques ResNet con el shortcut también hace que sea muy fácil para uno de los bloques aprender una función de identidad. Esto significa que puede apilar bloques ResNet adicionales con poco riesgo de dañar el rendimiento del conjunto de entrenamiento.\n",
    "\n",
    "En ese sentido, también hay alguna evidencia de que la facilidad de aprender una función de identidad explica el notable rendimiento de ResNets incluso más que las skip connections que ayudan con los vanishing gradients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizan **dos tipos principales de bloques en una ResNet**, dependiendo principalmente de si las dimensiones de entrada/salida son iguales o diferentes. \n",
    "Se implementará ambos: el `\"identity block\"` y el `\"convolutional block.\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'drive_download' from 'resnets_utils' (c:\\Users\\sandr\\Desktop\\Portafolio\\ResNet50 - SIGNS_Classification\\resnets_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-bd55bd2886e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomUniform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGlorotUniform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIdentity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mresnets_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrive_download\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'drive_download' from 'resnets_utils' (c:\\Users\\sandr\\Desktop\\Portafolio\\ResNet50 - SIGNS_Classification\\resnets_utils.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Add, Activation, BatchNormalization, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.initializers import RandomUniform, GlorotUniform, Identity, Constant\n",
    "from PIL import Image\n",
    "from resnets_utils import load_dataset, drive_download\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Identity block\n",
    "\n",
    "El bloque de identidad es el bloque estándar utilizado en ResNets y corresponde al caso en el que la activación de entrada (por ejemplo, $a^{[l]}$) tiene **la misma dimensión que la activación de salida** (por ejemplo, $a^{ [l+2]}$).\n",
    "\n",
    "<img src=\"images/idblock2_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "<caption><center> La Skip connection \"Omite sobre\" 2 capas. </center></caption>\n",
    "\n",
    "**Para acelerar el entrenamiento, se ha agregado un paso BatchNorm**. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio, implementará una versión un poco más poderosa de este bloque de identidad, en la que la skip connection \"salta\" 3 capas ocultas en lugar de 2 capas. Se parece a esto:\n",
    "\n",
    "<img src=\"images/idblock3_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "    <caption><center>Skip connection \"Omite sobre\" 3 capas.</center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos son los pasos individuales:\n",
    "\n",
    "Primer componente de la ruta principal:\n",
    "- El primer CONV2D tiene $F_1$ filtros de forma (1,1) y un paso de (1,1). Su padding es \"valid\". Use 0 como semilla para la inicialización aleatoria uniforme: `kernel_initializer = initializer(seed=0)`.\n",
    "- El primer BatchNorm está normalizando el eje de 'channels'.\n",
    "- Luego aplique la función de activación de ReLU. Esto no tiene hiperparámetros.\n",
    "\n",
    "Segundo componente de la ruta principal:\n",
    "- El segundo CONV2D tiene $F_2$ filtros de forma $(f,f)$ y un paso de (1,1). Su padding es \"same\". Use 0 como semilla para la inicialización aleatoria uniforme: `kernel_initializer = initializer(seed=0)`.\n",
    "- El segundo BatchNorm está normalizando el eje de 'channels'.\n",
    "- Luego aplique la función de activación de ReLU. Esto no tiene hiperparámetros.\n",
    "\n",
    "Tercer componente de la ruta principal:\n",
    "- El tercer CONV2D tiene $F_3$ filtros de forma (1,1) y un paso de (1,1). Su padding es \"valid\". Use 0 como semilla para la inicialización aleatoria uniforme: `kernel_initializer = initializer(seed=0)`.\n",
    "- El tercer BatchNorm está normalizando el eje de 'channels'.\n",
    "- Tenga en cuenta que **no** hay función de activación de ReLU en este componente.\n",
    "\n",
    "Último paso:\n",
    "- El `X_shortcut` y la salida de la tercera capa `X` se suman.\n",
    "- **Sugerencia**: La sintaxis se parecerá a `Add()([var1,var2])`\n",
    "- Luego aplique la función de activación de ReLU. Esto no tiene hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, training=True, initializer = RandomUniform):\n",
    "    # X: entrada, y tambien alimenta a la ultima capa (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    # f : int, especificando la forma de la ventana central de CONV para la ruta principal\n",
    "    # filters : Cantidad de filtros aplicados\n",
    "    # initializer : Inicializador de entradas\n",
    "    # training -- True: Comportarse en modo entrenamiento\n",
    "    #          -- False: Comportarse en modo de inferencia\n",
    "    F1,F2,F3 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "\n",
    "    # 1ra componente de la ruta principal\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = 1, padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = -1)(X, training = training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # 2da componente de la ruta principal\n",
    "    X = Conv2D(filters = F2, kernel_size = f, strides = 1, padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = -1)(X, training = training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # 3ra componente de la ruta principal\n",
    "    X = Conv2D(filters = F3, kernel_size = 1, strides = 1, padding = \"valid\", kernel_initializer = initializer(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = -1)(X, training = training)\n",
    "\n",
    "    # Paso final: Agregar el valor del shortcut a la ruta principal\n",
    "    X = Add()([X_shortcut, X])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Convolutional Block\n",
    "\n",
    "El **Bloque convolucional** de ResNet es el segundo tipo de bloque. Puede usar este tipo de bloque cuando **las dimensiones de entrada y salida no coinciden**. La diferencia con el bloque de identidad es que hay una capa CONV2D en la ruta del shortcut:\n",
    "\n",
    "<img src=\"images/convblock_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "\n",
    "* La capa CONV2D en la ruta del shortcut se usa para cambiar el tamaño de la entrada $x$ a una dimensión diferente, de modo que las dimensiones coincidan en la adición final necesaria para agregar el valor del shorcut nuevamente a la ruta principal.\n",
    "* Por ejemplo, para reducir la altura y el ancho de las dimensiones de activación en un factor de 2, puede usar una convolución de 1x1 con un stride de 2.\n",
    "* La capa CONV2D en la ruta del shortcut no utiliza ninguna función de activación no lineal. Su función principal es simplemente aplicar una función lineal (aprendida) que reduce la dimensión de la entrada, de modo que las dimensiones coincidan para el paso de adición posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los detalles del bloque convolucional son los siguientes.\n",
    "\n",
    "Primer componente de la ruta principal:\n",
    "- El primer CONV2D tiene $F_1$ filtros de forma (1,1) y un paso de (s,s). Su padding es \"valid\". Use 0 como la semilla `glorot_uniform` `kernel_initializer = initializer(seed=0)`.\n",
    "- El primer BatchNorm está normalizando el eje de 'channels'.\n",
    "- Luego aplique la función de activación de ReLU. Esto no tiene hiperparámetros.\n",
    "\n",
    "Segundo componente de la ruta principal:\n",
    "- El segundo CONV2D tiene $F_2$ filtros de forma (f,f) y un paso de (1,1). Su padding es \"same\". Use 0 como la semilla `glorot_uniform` `kernel_initializer = initializer(seed=0)`.\n",
    "- El segundo BatchNorm está normalizando el eje de 'channels'.\n",
    "- Luego aplique la función de activación de ReLU. Esto no tiene hiperparámetros.\n",
    "\n",
    "Tercer componente de la ruta principal:\n",
    "- El tercer CONV2D tiene $F_3$ filtros de forma (1,1) y un paso de (1,1). Su padding es \"valid\". Use 0 como la semilla `glorot_uniform` `kernel_initializer = initializer(seed=0)`.\n",
    "- El tercer BatchNorm está normalizando el eje de 'channels'. Tenga en cuenta que no hay una función de activación de ReLU en este componente.\n",
    "\n",
    "Ruta del shortcut:\n",
    "- El CONV2D tiene $F_3$ filtros de forma (1,1) y un paso de (s,s). Su relleno es \"valid\". Use 0 como la semilla `glorot_uniform` `kernel_initializer = initializer(seed=0)`.\n",
    "- El BatchNorm está normalizando el eje de 'channels'.\n",
    "\n",
    "Último paso:\n",
    "- El shortcut y los valores de la ruta principal se suman juntos.\n",
    "- Luego aplique la función de activación de ReLU. Esto no tiene hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, s=2, training=True, initializer=GlorotUniform):\n",
    "    # X: entrada, y tambien alimenta a la ultima capa (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    # f : int, especificando la forma de la ventana central de CONV para la ruta principal\n",
    "    # filters : Cantidad de filtros aplicados\n",
    "    # initializer : Inicializador de los parametros\n",
    "    #     training -- True: Comportarse en modo entrenamiento\n",
    "    #              -- False: Comportarse en modo de inferencia\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "    X_shortcut = X\n",
    "\n",
    "    # 1ra componente de la ruta principal\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = s, padding='valid', kernel_initializer=initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis=-1)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # 2da componente de la ruta principal\n",
    "    X = Conv2D(filters=F2, kernel_size = f, strides = 1, padding = 'same', kernel_initializer=initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis=-1)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # 3ra componente de la ruta principal\n",
    "    X = Conv2D(filters = F3, kernel_size = 1, strides = 1, padding = 'valid', kernel_initializer=initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = -1)(X, training = training)\n",
    "\n",
    "    # Ruta del shortcut\n",
    "    X_shortcut = Conv2D(filters = F3, kernel_size = 1, strides = s, padding = 'valid', kernel_initializer=initializer(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = -1)(X_shortcut, training = training)\n",
    "\n",
    "    # Paso final: Agregue valor del shortcut a la ruta principal (Use este orden [X, X_shortcut]) y páselo a través de una activación RELU\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creación de su primer modelo ResNet (50 capas)\n",
    "\n",
    "Ahora tiene los bloques necesarios para construir una ResNet muy profunda. La siguiente figura describe en detalle la arquitectura de esta red neuronal. \"ID BLOCK\" en el diagrama significa \"Identity block\" y \"ID BLOCK x3\" significa que debe apilar 3 bloques de identidad juntos.\n",
    "\n",
    "<img src=\"images/resnet_kiank.png\" style=\"width:850px;height:150px;\">\n",
    "<caption><center> <b>ResNet-50 model</b> </center></caption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los detalles de este modelo ResNet-50 son:\n",
    "- El Zero-padding rellena la entrada con un relleno de (3,3)\n",
    "- Stage 1:\n",
    "    - La convolución 2D tiene 64 filtros de forma (7,7) y utiliza un paso de (2,2).\n",
    "    - BatchNorm se aplica al eje de 'channels' de la entrada.\n",
    "    - MaxPooling utiliza una ventana (3,3) y un paso (2,2).\n",
    "- Stage 2:\n",
    "    - El bloque convolucional utiliza tres conjuntos de filtros de tamaño [64,64,256], \"f\" es 3 y \"s\" es 1.\n",
    "    - Los 2 bloques de identidad usan tres conjuntos de filtros de tamaño [64,64,256], y \"f\" es 3.\n",
    "- Stage 3:\n",
    "    - El bloque convolucional utiliza tres conjuntos de filtros de tamaño [128,128,512], \"f\" es 3 y \"s\" es 2.\n",
    "    - Los 3 bloques de identidad usan tres conjuntos de filtros de tamaño [128,128,512] y \"f\" es 3.\n",
    "- Stage 4:\n",
    "    - El bloque convolucional utiliza tres conjuntos de filtros de tamaño [256, 256, 1024], \"f\" es 3 y \"s\" es 2.\n",
    "    - Los 5 bloques de identidad utilizan tres conjuntos de filtros de tamaño [256, 256, 1024] y \"f\" es 3.\n",
    "- Etapa 5:\n",
    "    - El bloque convolucional utiliza tres conjuntos de filtros de tamaño [512, 512, 2048], \"f\" es 3 y \"s\" es 2.\n",
    "    - Los 2 bloques de identidad usan tres conjuntos de filtros de tamaño [512, 512, 2048] y \"f\" es 3.\n",
    "- El AveragePooling 2D utiliza una ventana de forma (2,2).\n",
    "- La capa 'Flatten' no tiene hiperparámetros.\n",
    "- La capa Totalmente Conectada (Densa) reduce su entrada al número de clases usando una activación softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (64,64,3), classes=6):\n",
    "    '''\n",
    "    Argumentos:\n",
    "     input_shape -- forma de las imágenes del conjunto de datos\n",
    "     clases -- número entero, número de clases\n",
    "\n",
    "     Devoluciones:\n",
    "     model -- una instancia de Model() en Keras\n",
    "    '''\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-padding\n",
    "    X = ZeroPadding2D((3,3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, kernel_size = 7, strides = 2, kernel_initializer = GlorotUniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = -1)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(pool_size = 3, strides = 2)(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, 3, [64,64,256], s=1)\n",
    "    X = identity_block(X, 3, [64,64,256])\n",
    "    X = identity_block(X, 3, [64,64,256])\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, 3, [128,128,512], s=2)\n",
    "    X = identity_block(X, 3, [128,128,512])\n",
    "    X = identity_block(X, 3, [128,128,512])\n",
    "    X = identity_block(X, 3, [128,128,512])\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, 3, [256, 256, 1024], s=2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, 3, [512, 512, 2048], s=2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "\n",
    "    # Paso final\n",
    "    X = AveragePooling2D(pool_size = 2)(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation = 'softmax', kernel_initializer=GlorotUniform(seed=0))(X)\n",
    "\n",
    "    # Creamos el modelo\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = ResNet50(input_shape = (64,64,3), classes = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 70, 70, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 64)   9472        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 64)   256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 64)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 15, 15, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 15, 15, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 15, 15, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 15, 15, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 15, 15, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 15, 15, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 15, 15, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 15, 15, 256)  16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 15, 15, 256)  16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 15, 15, 256)  1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 15, 15, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 15, 15, 256)  0           batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 15, 15, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 15, 15, 64)   16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 15, 15, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 15, 15, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 15, 15, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 15, 15, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 15, 15, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 15, 15, 256)  16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 15, 15, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 15, 15, 256)  0           activation_3[0][0]               \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 15, 15, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 15, 15, 64)   16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 15, 15, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 15, 15, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 15, 15, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 15, 15, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 15, 15, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 15, 15, 256)  16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 15, 15, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 15, 15, 256)  0           activation_6[0][0]               \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 15, 15, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 128)    32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 128)    512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 8, 128)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 128)    147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 128)    512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8, 8, 128)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 512)    66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 512)    131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 512)    2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 512)    2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 512)    0           batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 8, 512)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 128)    65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 128)    512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 128)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 128)    147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 128)    512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 128)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 512)    66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 512)    2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 512)    0           activation_12[0][0]              \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 512)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 128)    65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 128)    512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 128)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 128)    147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 128)    512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 128)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 512)    66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 512)    2048        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 512)    0           activation_15[0][0]              \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 512)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 128)    65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 128)    512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 128)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 8, 128)    147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 8, 128)    512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 128)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 8, 512)    66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 8, 8, 512)    2048        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 512)    0           activation_18[0][0]              \n",
      "                                                                 batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 512)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 4, 4, 256)    131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 4, 4, 256)    1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 4, 4, 256)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 4, 4, 256)    590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 4, 4, 256)    1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 4, 4, 256)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 4, 4, 1024)   263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 4, 4, 1024)   525312      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 4, 4, 1024)   4096        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 4, 4, 1024)   4096        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 4, 4, 1024)   0           batch_normalization_26[0][0]     \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 4, 4, 1024)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 4, 4, 256)    262400      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 4, 4, 256)    1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 4, 4, 256)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 4, 4, 256)    590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 4, 4, 256)    1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 4, 4, 256)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 4, 4, 1024)   263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 4, 4, 1024)   4096        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 4, 4, 1024)   0           activation_24[0][0]              \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 4, 4, 1024)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 4, 4, 256)    262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 4, 4, 256)    1024        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 4, 4, 256)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 4, 4, 256)    590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 4, 4, 256)    1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 4, 4, 256)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 4, 4, 1024)   263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 4, 4, 1024)   4096        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 4, 4, 1024)   0           activation_27[0][0]              \n",
      "                                                                 batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 4, 4, 1024)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 4, 4, 256)    262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 4, 4, 256)    1024        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 4, 4, 256)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 4, 4, 256)    590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 4, 4, 256)    1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 4, 4, 256)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 4, 4, 1024)   263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 4, 4, 1024)   4096        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 4, 4, 1024)   0           activation_30[0][0]              \n",
      "                                                                 batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 4, 4, 1024)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 4, 4, 256)    262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 4, 4, 256)    1024        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 4, 4, 256)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 4, 4, 256)    590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 4, 4, 256)    1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 4, 4, 256)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 4, 4, 1024)   263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 4, 4, 1024)   4096        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 4, 4, 1024)   0           activation_33[0][0]              \n",
      "                                                                 batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 4, 4, 1024)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 4, 4, 256)    262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 4, 4, 256)    1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 4, 4, 256)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 4, 4, 256)    590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 4, 4, 256)    1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 4, 4, 256)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 4, 4, 1024)   263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 4, 4, 1024)   4096        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 4, 4, 1024)   0           activation_36[0][0]              \n",
      "                                                                 batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 4, 4, 1024)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 2, 2, 512)    524800      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 2, 2, 512)    2048        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 2, 2, 512)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 2, 2, 512)    2359808     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 2, 2, 512)    2048        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 2, 2, 512)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 2, 2, 2048)   1050624     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 2, 2, 2048)   2099200     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 2, 2, 2048)   8192        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 2, 2, 2048)   8192        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 2, 2, 2048)   0           batch_normalization_45[0][0]     \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 2, 2, 2048)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 2, 2, 512)    1049088     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 2, 2, 512)    2048        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 2, 2, 512)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 2, 2, 512)    2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 2, 2, 512)    2048        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 2, 2, 512)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 2, 2, 2048)   1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 2, 2, 2048)   8192        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 2, 2, 2048)   0           activation_42[0][0]              \n",
      "                                                                 batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 2, 2, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 2, 2, 512)    1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 2, 2, 512)    2048        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 2, 2, 512)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 2, 2, 512)    2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 2, 2, 512)    2048        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 2, 2, 512)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 2, 2, 2048)   1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 2, 2, 2048)   8192        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 2, 2, 2048)   0           activation_45[0][0]              \n",
      "                                                                 batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 2, 2, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 2048)   0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 6)            12294       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,600,006\n",
      "Trainable params: 23,546,886\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo ahora está listo para ser entrenado. ¡Lo único que necesita ahora es un conjunto de datos!\n",
    "\n",
    "Carguemos el conjunto de datos SIGNS.\n",
    "\n",
    "<img src=\"images/signs_data_kiank.png\" style=\"width:450px;height:250px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = ru.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "# Normalizamos imagenes\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "# Convertimos las target de training y test a matrices one-hot\n",
    "Y_train = tf.one_hot(Y_train_orig.reshape(-1), 6).numpy()\n",
    "Y_test = tf.one_hot(Y_test_orig.reshape(-1), 6).numpy()\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute la siguiente celda para entrenar su modelo en 2 épocas con un tamaño de lote de 32. En una CPU, le llevará alrededor de 5 minutos por época."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "34/34 [==============================] - 122s 4s/step - loss: 0.2866 - accuracy: 0.9083\n",
      "Epoch 2/2\n",
      "34/34 [==============================] - 125s 4s/step - loss: 0.1602 - accuracy: 0.9380\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs = 2, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cómo se comporta este modelo (entrenado en solo dos épocas) en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 482ms/step - loss: 0.8463 - accuracy: 0.7250\n",
      "Loss = 0.8463267087936401\n",
      "Test Accuracy = 0.7250000238418579\n"
     ]
    }
   ],
   "source": [
    "ev = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(ev[0]))\n",
    "print (\"Test Accuracy = \" + str(ev[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.286559</td>\n",
       "      <td>0.908333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.160234</td>\n",
       "      <td>0.937963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy\n",
       "0  0.286559  0.908333\n",
       "1  0.160234  0.937963"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A los efectos de esta tarea, le hemos pedido que entrene el modelo durante solo dos épocas. Se puede ver que logra rendimientos pobres, si lo desea. Obtenemos un rendimiento mucho mejor cuando entrenamos durante ~20 épocas, pero esto tomará más de una hora cuando entrenamos en una CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando una GPU, hemos entrenado los pesos de nuestro propio modelo ResNet50 en el conjunto de datos de SIGNS. Puede cargar y ejecutar nuestro modelo entrenado en el conjunto de prueba en las celdas a continuación. Puede tardar ≈1 min en cargar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Descarga](https://drive.google.com/file/d/1GeVMC2f3jf0uufR3FP2u1qDUWw1i-F54/view?usp=sharing) , URL del modelo entrenado con GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('ResNet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 7s 496ms/step - loss: 0.5302 - accuracy: 0.8667\n",
      "Loss = 0.5301783680915833\n",
      "Test Accuracy = 0.8666666746139526\n"
     ]
    }
   ],
   "source": [
    "ev = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(ev[0]))\n",
    "print (\"Test Accuracy = \" + str(ev[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Prueba en tu propia imagen***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = \n",
      "[[3.5465923e-06 2.8655684e-04 9.9951088e-01 2.0490866e-07 1.9831577e-04\n",
      "  4.2891079e-07]]\n"
     ]
    }
   ],
   "source": [
    "img_path = 'images/my_image.jpg'\n",
    "img = Image.open(img_path)\n",
    "img_resize = cv2.resize(np.array(img), (64, 64), interpolation =  cv2.INTER_CUBIC).reshape(1,64,64,3)\n",
    "x = img_resize/255.\n",
    "print(\"class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = \")\n",
    "y = model.predict(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen dio como predicción  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"La imagen dio como predicción \", y.argmax())\n",
    "plt.imshow(x[0])\n",
    "plt.axis(\"off\")\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4edecc0c6a4f0e1e3de79ca77741107a175241f6f71b1c161b36dd6ac31a9479"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
